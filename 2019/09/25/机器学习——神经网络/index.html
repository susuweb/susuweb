<!DOCTYPE html><html class="theme-next muse use-motion" lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="theme-color" content="#222"><script src="/lib/pace/pace.min.js?v=1.0.2"></script><link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"><link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css"><link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4"><link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222"><meta name="keywords" content="Hexo, NexT"><link rel="alternate" href="/atom.xml" title="Jakey" type="application/atom+xml"><meta name="description" content="@TOC什么是神经网络神经网络，是借鉴了生物神经网络的工作原理形成的一种数学模型，是机器学习算法中的一种，既可以用来做有监督的任务，如分类、视觉识别等，也可以用来做无监督的任务。同时能处理复杂的非线性问题，基本结构是神经元。基本结构为：输入（树突）——&amp;gt;处理（神经元）——&amp;gt;输出（轴突）如图：多个神经元组成的就是神经网络：这是一个4层结构的神经网络，ayer1为输入层，layer4为输出"><meta property="og:type" content="article"><meta property="og:title" content="Jakey"><meta property="og:url" content="http://jakey.vip/2019/09/25/机器学习——神经网络/index.html"><meta property="og:site_name" content="Jakey"><meta property="og:description" content="@TOC什么是神经网络神经网络，是借鉴了生物神经网络的工作原理形成的一种数学模型，是机器学习算法中的一种，既可以用来做有监督的任务，如分类、视觉识别等，也可以用来做无监督的任务。同时能处理复杂的非线性问题，基本结构是神经元。基本结构为：输入（树突）——&amp;gt;处理（神经元）——&amp;gt;输出（轴突）如图：多个神经元组成的就是神经网络：这是一个4层结构的神经网络，ayer1为输入层，layer4为输出"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvOTgxMjExLzIwMTgwNi85ODEyMTEtMjAxODA2MTkyMjQyNDQ0MTgtNTY0MDAyNjM5LnBuZw?x-oss-process=image/format,png"><meta property="og:image" content="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvOTgxMjExLzIwMTgwNi85ODEyMTEtMjAxODA2MTkyMjQ2MTg1NzQtMTM1MDUyNTE3MS5wbmc?x-oss-process=image/format,png"><meta property="og:image" content="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvOTgxMjExLzIwMTgwNi85ODEyMTEtMjAxODA2MjUyMzAwMjMyMjQtNTI1MzM3NDQxLnBuZw?x-oss-process=image/format,png"><meta property="og:image" content="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvOTgxMjExLzIwMTgwNi85ODEyMTEtMjAxODA2MjUyMzAyMTUwMDAtMTQyMTczMDIzNy5wbmc?x-oss-process=image/format,png"><meta property="og:image" content="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvOTgxMjExLzIwMTgwNi85ODEyMTEtMjAxODA2MjYyMTMyNTQ2NzAtNzQ3MTgzMTU5LnBuZw?x-oss-process=image/format,png"><meta property="og:image" content="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvOTgxMjExLzIwMTgwNi85ODEyMTEtMjAxODA2MjYyMTM0NTg0MTEtMTk1MzE2NjEwLnBuZw?x-oss-process=image/format,png"><meta property="og:image" content="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvOTgxMjExLzIwMTgwNi85ODEyMTEtMjAxODA2MjYyMTU4MzU3MDMtMTA5NzAyMDk1OC5wbmc?x-oss-process=image/format,png"><meta property="og:image" content="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvOTgxMjExLzIwMTgwNi85ODEyMTEtMjAxODA2MjYyMjAxMTM5NzAtMTQ1MDg3NDg0MS5wbmc?x-oss-process=image/format,png"><meta property="og:image" content="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvOTgxMjExLzIwMTgwNi85ODEyMTEtMjAxODA2MjYyMzM5NDgwNDgtNTE2Njg4NTQ0LnBuZw?x-oss-process=image/format,png"><meta property="og:image" content="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvOTgxMjExLzIwMTgwNi85ODEyMTEtMjAxODA2MjYyMzMwMjY2NjAtOTA2NTUzMzAucG5n?x-oss-process=image/format,png"><meta property="og:image" content="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvOTgxMjExLzIwMTgwNi85ODEyMTEtMjAxODA2MjYyMzMzNTQ5OTItNTIzNzQ3MzI0LnBuZw?x-oss-process=image/format,png"><meta property="og:updated_time" content="2019-09-25T12:36:23.822Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Jakey"><meta name="twitter:description" content="@TOC什么是神经网络神经网络，是借鉴了生物神经网络的工作原理形成的一种数学模型，是机器学习算法中的一种，既可以用来做有监督的任务，如分类、视觉识别等，也可以用来做无监督的任务。同时能处理复杂的非线性问题，基本结构是神经元。基本结构为：输入（树突）——&amp;gt;处理（神经元）——&amp;gt;输出（轴突）如图：多个神经元组成的就是神经网络：这是一个4层结构的神经网络，ayer1为输入层，layer4为输出"><meta name="twitter:image" content="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvOTgxMjExLzIwMTgwNi85ODEyMTEtMjAxODA2MTkyMjQyNDQ0MTgtNTY0MDAyNjM5LnBuZw?x-oss-process=image/format,png"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Muse",version:"5.1.4",sidebar:{position:"left",display:"post",offset:12,b2t:!1,scrollpercent:!1,onmobile:!1},fancybox:!0,tabs:!0,motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},duoshuo:{userId:"0",author:"Author"},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><link rel="canonical" href="http://jakey.vip/2019/09/25/机器学习——神经网络/"><title>| Jakey</title></head><body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN"><div class="container sidebar-position-left page-post-detail"><div class="headband"></div><a href="https://github.com/susuweb/susuweb.github.io.git" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewbox="0 0 250 250" style="fill:#151513;color:#fff;position:absolute;top:0;border:0;right:0" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">Jakey</span> <span class="logo-line-after"><i></i></span></a></div><p class="site-subtitle">成为一个厉害的普通人</p></div><div class="site-nav-toggle"><button><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>Home</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>Archives</a></li></ul></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://jakey.vip/2019/09/25/机器学习——神经网络/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="Jakey"><meta itemprop="description" content><meta itemprop="image" content="/images/avatar.gif"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Jakey"></span><header class="post-header"><h1 class="post-title" itemprop="name headline"></h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">Posted on</span> <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-09-25T20:38:02+08:00">2019-09-25</time></span></div></header><div class="post-body" itemprop="articleBody"><p>@<a href="机器学习--神经网络">TOC</a></p><h1 id="什么是神经网络"><a href="#什么是神经网络" class="headerlink" title="什么是神经网络"></a>什么是神经网络</h1><p>神经网络，是借鉴了生物神经网络的工作原理形成的一种数学模型，是机器学习算法中的一种，既可以用来做有监督的任务，如分类、视觉识别等，也可以用来做无监督的任务。同时能处理复杂的非线性问题，基本结构是神经元。<br>基本结构为：</p><blockquote><p>输入（树突）——&gt;处理（神经元）——&gt;输出（轴突）</p></blockquote><p>如图：<br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvOTgxMjExLzIwMTgwNi85ODEyMTEtMjAxODA2MTkyMjQyNDQ0MTgtNTY0MDAyNjM5LnBuZw?x-oss-process=image/format,png" alt="Alt"><br>多个神经元组成的就是神经网络：<br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvOTgxMjExLzIwMTgwNi85ODEyMTEtMjAxODA2MTkyMjQ2MTg1NzQtMTM1MDUyNTE3MS5wbmc?x-oss-process=image/format,png" alt="Alt"><br>这是一个4层结构的神经网络，ayer1为输入层，layer4为输出层，layer2,layer3为隐藏层，即神经网络的结构由输入层，隐藏层，输出层构成。其中除了输入层以外，每一层的输入都是上一层的输出。</p><h1 id="神经网络数学原理"><a href="#神经网络数学原理" class="headerlink" title="神经网络数学原理"></a>神经网络数学原理</h1><p>单个神经元的组成包含两部分，权重和偏置，每个输入值进入神经元都会进行y=wx+b的计算，其中w为权重，b为偏置，x为输出值，y为单个输出值的结果，经过激活函数即神经元后输出结果为f(wx+b)，f为激活函数，如果有多个输入值的话输出值为f(w1x1+w2x2+…+wnxn)。</p><h2 id="激活函数的作用"><a href="#激活函数的作用" class="headerlink" title="激活函数的作用"></a>激活函数的作用</h2><p>激活函数也称为映射函数，可以对计算结果进行非线性转换，提升神经网络的表达能力，从而能够处理线性不可分的问题，比如语音识别和图像识别等，常见的激活函数有sigmoid,tanh,relu…等等。</p><h2 id="sigmoid激活函数"><a href="#sigmoid激活函数" class="headerlink" title="sigmoid激活函数"></a>sigmoid激活函数</h2><p>表达式为：<br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvOTgxMjExLzIwMTgwNi85ODEyMTEtMjAxODA2MjUyMzAwMjMyMjQtNTI1MzM3NDQxLnBuZw?x-oss-process=image/format,png" alt="Alt"><br>其图形为一个s型曲线，会将所有的输入结果映射到0-1之间，图形样式如下：<br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvOTgxMjExLzIwMTgwNi85ODEyMTEtMjAxODA2MjUyMzAyMTUwMDAtMTQyMTczMDIzNy5wbmc?x-oss-process=image/format,png" alt="Alt"><br>sigmoid通常用于处理分类问题，如逻辑回归算法就是使用sigmoid处理分类问题。</p><h2 id="tanh激活函数"><a href="#tanh激活函数" class="headerlink" title="tanh激活函数"></a>tanh激活函数</h2><p>tanh表达式为：<br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvOTgxMjExLzIwMTgwNi85ODEyMTEtMjAxODA2MjYyMTMyNTQ2NzAtNzQ3MTgzMTU5LnBuZw?x-oss-process=image/format,png" alt="Alt"><br>tanh函数的图形和sigmoid类似，不同的是它是将输入值映射到-1<del>1之间。它的图形如下图所示：<br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvOTgxMjExLzIwMTgwNi85ODEyMTEtMjAxODA2MjYyMTM0NTg0MTEtMTk1MzE2NjEwLnBuZw?x-oss-process=image/format,png" alt="Alt"><br>由于tanh函数的压缩范围在-1</del>1之间，因而它的输出基本是0均值，即下一层的输入为0均值，这使得tanh函数的收敛速度要快于sigmoid函数。</p><p>假设后层神经元的输入都为正(e.g. x&gt;0 elementwise in f=wTx+b),那么对w求局部梯度则都为正，这样在反向传播的过程中w要么都往正方向更新，要么都往负方向更新，导致有一种捆绑的效果，使得收敛缓慢。这是sigmoid函数容易出现的问题，而tanh函数的映射特点很好的避开了这个问题。因而在实际使用中，人们会更经常使用tanh函数作为激活函数。</p><p>sigmoid函数和tanh函数的共同问题是在求导过程中可能出现梯度消失的现象</p><h2 id="激活函数ReLU"><a href="#激活函数ReLU" class="headerlink" title="激活函数ReLU"></a>激活函数ReLU</h2><p>表达式为：<br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvOTgxMjExLzIwMTgwNi85ODEyMTEtMjAxODA2MjYyMTU4MzU3MDMtMTA5NzAyMDk1OC5wbmc?x-oss-process=image/format,png" alt="Alt">图形如下：<br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvOTgxMjExLzIwMTgwNi85ODEyMTEtMjAxODA2MjYyMjAxMTM5NzAtMTQ1MDg3NDg0MS5wbmc?x-oss-process=image/format,png" alt="Alt"><br>它相比于sigmoid和tanh有更快的收敛速度，同时不会出现梯度消失的问题。另外从函数表达中可以知道，输入小于0时，输出会变成0，这就使得神经网络变得稀疏，并减少参数的相互依存关系，缓解过拟合问题，而且由于函数的本身特性，不涉及指数等操作，实现起来也更加容易。</p><p>但它也有缺点，ReLU单元脆弱且可能会在训练中死去。例如，大的梯度流经过ReLU单元时可能导致神经不会在以后任何数据节点再被激活。当这发生时，经过此单元的梯度将永远为零。ReLU单元可能不可逆地在训练中的数据流中关闭。例如，比可能会发现当学习速率过快时你40%的网络都“挂了”（神经元在此后的整个训练中都不激活）。当学习率设定恰当时，这种事情会更少出现。</p><h2 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h2><p>反向传播的目的在于通过不断的回传误差，对权重进行更新，重新计算输出，最终从已有的输入值经过神经网络得到我们需要的结果。要理解反向传播，我们需要先理解前向传播的过程。</p><p>假设一个三层神经网络，在随机分配获得权重的情况下，数据从输入层——&gt;隐藏层——&gt;输出层过程可以称为前向传播，当然在这个过程中会涉及很多数学计算，最终会在输出层有一个输出值，而输出值和我们需要的目标值或实际值之间一般会存在差距，即我们通常说的误差。</p><p>接下来，根据误差进行反向更新权值的过程就称之为误差的反向传播，要对权值进行更新，我们需要评估权值对误差产生的影响大小，这个通过计算误差对权值的偏导值进行估计，过程中有一个重要的概念是链式法则。</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvOTgxMjExLzIwMTgwNi85ODEyMTEtMjAxODA2MjYyMzM5NDgwNDgtNTE2Njg4NTQ0LnBuZw?x-oss-process=image/format,png" alt="Alt"><br>其中链式求导表现为：<br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvOTgxMjExLzIwMTgwNi85ODEyMTEtMjAxODA2MjYyMzMwMjY2NjAtOTA2NTUzMzAucG5n?x-oss-process=image/format,png" alt="Alt"><br>即误差对权值的偏导值可以看成每一个反向计算步骤的偏导值的乘积。</p><p>在得到误差对权值的偏导值后，我们就可以对权值进行更新，更新公式为：<br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvOTgxMjExLzIwMTgwNi85ODEyMTEtMjAxODA2MjYyMzMzNTQ5OTItNTIzNzQ3MzI0LnBuZw?x-oss-process=image/format,png" alt="Alt"><br>其中n是学习速率。</p><p>按照相同的步骤对所有的权重进行更新，然后再次进行前向传播，获得新误差，再反向传播更新权值，不断的重复这个过程，直到误差达到我们设定的阈值范围结束迭代。</p></div><div><div><div style="text-align:center;color:#ccc;font-size:14px">-------------本文结束感谢您的阅读-------------</div></div></div><footer class="post-footer"><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/2019/07/30/my first blog in jakey/" rel="next" title="my first blog in jakey"><i class="fa fa-chevron-left"></i> my first blog in jakey</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"></div></div></footer></div></article><div class="post-spread"></div></div></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">Table of Contents</li><li class="sidebar-nav-overview" data-target="site-overview-wrap">Overview</li></ul><section class="site-overview-wrap sidebar-panel"><div class="site-overview"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><p class="site-author-name" itemprop="name">Jakey</p><p class="site-description motion-element" itemprop="description"></p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">3</span> <span class="site-state-item-name">posts</span></a></div></nav><div class="feed-link motion-element"><a href="/atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/susuweb" target="_blank" title="GitHub"><i class="fa fa-fw fa-github"></i>GitHub</a></span></div></div></section><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#什么是神经网络"><span class="nav-number">1.</span> <span class="nav-text">什么是神经网络</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#神经网络数学原理"><span class="nav-number">2.</span> <span class="nav-text">神经网络数学原理</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#激活函数的作用"><span class="nav-number">2.1.</span> <span class="nav-text">激活函数的作用</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#sigmoid激活函数"><span class="nav-number">2.2.</span> <span class="nav-text">sigmoid激活函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#tanh激活函数"><span class="nav-number">2.3.</span> <span class="nav-text">tanh激活函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#激活函数ReLU"><span class="nav-number">2.4.</span> <span class="nav-text">激活函数ReLU</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#反向传播"><span class="nav-number">2.5.</span> <span class="nav-text">反向传播</span></a></li></ol></li></ol></div></div></section></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div class="copyright">&copy; <span itemprop="copyrightYear">2019</span> <span class="with-love"><i class="fa fa-user"></i> </span><span class="author" itemprop="copyrightHolder">Jakey</span></div><div class="powered-by"><i class="fa fa-user-md"></i><span id="busuanzi_container_site_pv"> 本站访客数:<span id="busuanzi_value_site_pv"></span><span class="post-meta-divider">|</span></span></div><div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div><span class="post-meta-divider">|</span><div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script><script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script><script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script><script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script><script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script><script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script></body></html>